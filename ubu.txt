
=== SPARK / HADOOP COMMANDS ===
start-dfs.sh
start-yarn.sh
hdfs dfs -ls /
hdfs dfs -put localfile.txt /user/hadoop/
hdfs dfs -get /user/hadoop/file.txt localfile.txt
spark-submit --class org.apache.spark.examples.JavaWordCount wordcount.jar input.txt output

=== SPARK WORDCOUNT EXAMPLE (Python) ===
from pyspark import SparkContext
sc = SparkContext("local", "WordCountApp")
text_file = sc.textFile("input.txt")
counts = text_file.flatMap(lambda line: line.split())                   .map(lambda word: (word, 1))                   .reduceByKey(lambda a, b: a + b)
counts.saveAsTextFile("output")
sc.stop()

=== OPENMP / MPI INSTALLATION ===
sudo apt update
sudo apt install build-essential libomp-dev mpich mpich-doc
gcc -fopenmp omp_program.c -o omp_program
mpicc mpi_program.c -o mpi_program
mpirun -np 4 ./mpi_program

=== OPENMP EXAMPLES ===
#include <stdio.h>
#include <omp.h>
int main() {
    int sum = 0;
    #pragma omp parallel for reduction(+:sum)
    for(int i=1;i<=100;i++) sum += i;
    printf("Sum = %d\n", sum);
    return 0;
}

#include <stdio.h>
#include <omp.h>
int main() {
    int x = 5;
    #pragma omp parallel for firstprivate(x) lastprivate(x)
    for(int i=0;i<4;i++) {
        x += i;
        printf("Thread %d: x=%d\n", omp_get_thread_num(), x);
    }
    printf("After loop, x=%d\n", x);
    return 0;
}

#include <stdio.h>
#include <omp.h>
int main() {
    int sum = 0;
    #pragma omp parallel for
    for(int i=1;i<=10;i++) {
        #pragma omp critical
        sum += i;
    }
    printf("Sum = %d\n", sum);
    return 0;
}

=== MPI SAMPLE PROGRAM ===
#include <stdio.h>
#include <mpi.h>
int main(int argc, char** argv) {
    MPI_Init(NULL, NULL);
    int world_size;
    MPI_Comm_size(MPI_COMM_WORLD, &world_size);
    int world_rank;
    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);
    printf("Hello from rank %d out of %d\n", world_rank, world_size);
    MPI_Finalize();
    return 0;
}
